import logging
from datetime import datetime
from typing import Optional, Union

import numpy as np
import pandas as pd
import psycopg2
import streamlit as st
from psycopg2 import OperationalError, sql

from streaming.config import AppConfig


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
)
LOGGER = logging.getLogger("streamlit-ui")

cfg = AppConfig()
st.set_page_config(page_title="Fraud Monitoring", page_icon="üõ°Ô∏è", layout="wide")
st.title("üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–Ω—Ç–∏—Ñ—Ä–æ–¥–∞")


@st.cache_resource(show_spinner=False)
def get_db_connection():
    return psycopg2.connect(
        host=cfg.database.host,
        port=cfg.database.port,
        dbname=cfg.database.database,
        user=cfg.database.user,
        password=cfg.database.password,
    )


def fetch_dataframe(
    query: Union[sql.SQL, str],
    params: Optional[tuple] = None,
) -> pd.DataFrame:
    try:
        conn = get_db_connection()
        dataframe = pd.read_sql_query(
            query if isinstance(query, str) else query.as_string(conn),
            conn,
            params=params,
        )
        return dataframe
    except OperationalError:
        st.error(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö. "
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä Postgres –∑–∞–ø—É—â–µ–Ω."
        )
        raise
    except psycopg2.errors.UndefinedTable:
        st.warning("–¢–∞–±–ª–∏—Ü–∞ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –ø–æ–∫–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö.")
        return pd.DataFrame()


st.sidebar.header("–ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
limit = st.sidebar.slider(
    "–°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å",
    min_value=50,
    max_value=500,
    value=150,
    step=50,
)

if st.sidebar.button("–û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
    st.rerun()

summary_df = fetch_dataframe(
    "SELECT "
    "COUNT(*) AS total, "
    "SUM(CASE WHEN fraud_flag = 1 THEN 1 ELSE 0 END) AS frauds, "
    "AVG(score) AS avg_score, "
    "MAX(score) AS max_score, "
    "MIN(processed_at) AS first_seen, "
    "MAX(processed_at) AS last_seen "
    f"FROM {cfg.database.table_name}"
)

recent_df = fetch_dataframe(
    sql.SQL(
        "SELECT transaction_id, score, fraud_flag, processed_at "
        "FROM {table} "
        "ORDER BY processed_at DESC "
        "LIMIT %s"
    ).format(table=sql.Identifier(cfg.database.table_name)),
    params=(limit,),
)

fraud_df = fetch_dataframe(
    sql.SQL(
        "SELECT transaction_id, score, fraud_flag, processed_at "
        "FROM {table} "
        "WHERE fraud_flag = 1 "
        "ORDER BY processed_at DESC "
        "LIMIT 10"
    ).format(table=sql.Identifier(cfg.database.table_name))
)

if summary_df.empty or recent_df.empty:
    st.info(
        "–ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ Kafka, "
        "–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—è–≤—è—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏."
    )
    st.stop()


summary = summary_df.iloc[0]
total = int(summary["total"])
frauds = int(summary["frauds"] or 0)
fraud_share = frauds / total if total else 0.0
avg_score = float(summary["avg_score"] or 0.0)
max_score = float(summary["max_score"] or 0.0)
last_seen = summary["last_seen"]

metrics_cols = st.columns(4)
metrics_cols[0].metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", f"{total:,}".replace(",", " "))
metrics_cols[1].metric(
    "–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö",
    f"{frauds:,}".replace(",", " "),
    delta=f"{fraud_share * 100:.1f} %",
)
metrics_cols[2].metric("–°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä", f"{avg_score:.3f}")
metrics_cols[3].metric(
    "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä",
    f"{max_score:.3f}",
    delta="–ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á" if total else None,
)

if pd.notna(last_seen):
    last_seen_ts = pd.to_datetime(last_seen)
    st.caption(f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∏—Ç—Ä–∏–Ω—ã: {last_seen_ts:%d.%m.%Y %H:%M:%S}")

recent_df["processed_at"] = pd.to_datetime(recent_df["processed_at"])
timeline_df = recent_df.sort_values("processed_at")

chart_col, hist_col = st.columns(2)
with chart_col:
    st.subheader("–î–∏–Ω–∞–º–∏–∫–∞ —Å–∫–æ—Ä–∏–Ω–≥–∞")
    st.line_chart(
        timeline_df.set_index("processed_at")["score"],
        height=280,
    )

with hist_col:
    st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–∏–Ω–≥–æ–≤")
    counts, bin_edges = np.histogram(recent_df["score"], bins=15, range=(0, 1))
    hist_df = pd.DataFrame(
        {
            "–ò–Ω—Ç–µ—Ä–≤–∞–ª": [
                f"{bin_edges[i]:.2f}-{bin_edges[i + 1]:.2f}"
                for i in range(len(bin_edges) - 1)
            ],
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": counts,
        }
    ).set_index("–ò–Ω—Ç–µ—Ä–≤–∞–ª")
    st.bar_chart(hist_df, height=280)

st.subheader("–ü–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
st.dataframe(
    recent_df.rename(
        columns={
            "transaction_id": "Transaction ID",
            "score": "Score",
            "fraud_flag": "Fraud",
            "processed_at": "Processed At",
        }
    ).style.format({"Score": "{:.4f}"}),
    use_container_width=True,
    hide_index=True,
)

st.subheader("–§—Ä–æ–¥–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è")
if fraud_df.empty:
    st.info("–ü–æ–∫–∞ –Ω–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å —Ñ–ª–∞–≥–æ–º —Ñ—Ä–æ–¥–∞. –•–æ—Ä–æ—à–∏–π –∑–Ω–∞–∫!")
else:
    fraud_df["processed_at"] = pd.to_datetime(fraud_df["processed_at"])
    st.dataframe(
        fraud_df.rename(
            columns={
                "transaction_id": "Transaction ID",
                "score": "Score",
                "fraud_flag": "Fraud",
                "processed_at": "Processed At",
            }
        ).style.format({"Score": "{:.4f}"}),
        use_container_width=True,
        hide_index=True,
    )
    flagged_trend = fraud_df.sort_values("processed_at")
    st.line_chart(
        flagged_trend.set_index("processed_at")["score"],
        height=220,
    )

st.caption(
    "–î–∞–Ω–Ω—ã–µ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∏–∑ PostgreSQL. "
    "Kafka ‚Üí inference ‚Üí Postgres ‚Üí Streamlit."
)
