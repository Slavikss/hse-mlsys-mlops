# Архитектура системы детекции фрода

## Обзор

Система детекции фрода представляет собой **потоковый конвейер обработки транзакций** в реальном времени, построенный на основе микросервисной архитектуры. Система использует Apache Kafka в качестве message broker для асинхронной передачи данных между компонентами, PostgreSQL для хранения результатов и Streamlit для визуализации.

Архитектура системы спроектирована с использованием методологии **C4 (Context, Containers, Components, Code)** и представлена на двух уровнях детализации.

---

## Контекстная диаграмма (C4 Level 1)

### Назначение

Контекстная диаграмма показывает систему детекции фрода как единое целое и её взаимодействие с внешними акторами и системами.

### Основные акторы

1. **Аналитик безопасности** — просматривает результаты детекции фрода через веб-интерфейс, анализирует подозрительные транзакции.
2. **Data Scientist** — обучает и обновляет ML-модель, загружает новые версии модели в систему.

### Внешние системы

1. **Платёжная система** — генерирует поток транзакций для анализа (имитируется через CSV-файл и producer).
2. **Система мониторинга** — собирает метрики производительности и логи для observability.
3. **Система оповещений** — получает критические алерты о подозрительных транзакциях.

### Основные взаимодействия

- Платёжная система отправляет транзакции в систему детекции фрода через Kafka (формат JSON).
- Система обрабатывает транзакции и предоставляет результаты аналитику через веб-дашборд (HTTPS/WebSocket).
- Data Scientist обновляет модель путём замены файлов в Docker volumes.
- Система отправляет метрики в систему мониторинга и алерты в систему оповещений.

### Ключевые характеристики

- **Пропускная способность**: 1000+ транзакций/сек
- **Латентность**: < 100ms на транзакцию
- **Доступность**: 99.9%

---

## Диаграмма компонентов (C4 Level 3)

### Назначение

Диаграмма компонентов детализирует внутреннюю структуру системы, показывая микросервисы, их компоненты и потоки данных между ними.

### Архитектурные компоненты

#### 1. Transaction Producer Service

**Назначение**: Имитирует поток транзакций от платёжной системы.

**Компоненты**:
- **CSV Reader** — читает транзакции из файла `test.csv`.
- **Kafka Producer** — публикует транзакции в Kafka топик `transactions`.

**Технологии**: Python, kafka-python

**Конфигурация**:
- Частота отправки: 0.5 сек между транзакциями (настраивается через `PRODUCER_SLEEP_SECONDS`)
- Режим работы: циклический или однократный (`PRODUCER_REPEAT`)

---

#### 2. Fraud Scoring Service (детализация)

**Назначение**: Основной сервис скоринга транзакций с использованием ML-модели.

**Компоненты**:

##### 2.1. Kafka Consumer
- **Функция**: Читает транзакции из топика `transactions`
- **Технология**: kafka-python
- **Consumer Group**: `fraud-scorer`
- **Commit Strategy**: Manual commit после успешной обработки

##### 2.2. Feature Preprocessor
- **Функция**: Препроцессинг данных и feature engineering
- **Технология**: pandas, numpy
- **Логика**: 
  - Обработка категориальных признаков
  - Создание временных признаков (час, день недели)
  - Агрегации по мерчанту и держателю карты
  - Нормализация числовых признаков
- **Источник**: `source/train/preprocess_data.py`

##### 2.3. ML Inference Engine
- **Функция**: Применение модели машинного обучения для предсказания фрода
- **Технология**: CatBoost (бинарная классификация)
- **Вход**: DataFrame с подготовленными признаками
- **Выход**: Вероятность фрода [0..1]
- **Модель**: `artifacts/catboost_model.cbm`
- **Метаданные**: `artifacts/feature_metadata.json` (список признаков, порог классификации)

##### 2.4. Score Publisher
- **Функция**: Публикация результатов скоринга в Kafka
- **Технология**: kafka-python
- **Формат выходного сообщения**:
  ```json
  {
    "transaction_id": "uuid",
    "score": 0.9234,
    "fraud_flag": 1,
    "scored_at": "2024-11-15T12:34:56Z"
  }
  ```

**Производительность**:
- Латентность: < 50ms на транзакцию
- Throughput: 1000+ транзакций/сек (с горизонтальным масштабированием)

---

#### 3. Score Writer Service

**Назначение**: Сохранение результатов скоринга в базу данных.

**Компоненты**:
- **Score Consumer** — читает результаты из топика `scores`.
- **Database Writer** — записывает данные в PostgreSQL с использованием UPSERT операций.

**Технологии**: Python, kafka-python, psycopg2

**Consumer Group**: `fraud-score-writer`

**Схема таблицы**:
```sql
CREATE TABLE transaction_scores (
    transaction_id TEXT PRIMARY KEY,
    score DOUBLE PRECISION NOT NULL,
    fraud_flag SMALLINT NOT NULL,
    processed_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);
```

---

#### 4. Web UI (Streamlit Dashboard)

**Назначение**: Визуализация результатов детекции фрода для аналитиков.

**Компоненты**:
- **Streamlit Dashboard** — веб-интерфейс с графиками и таблицами.
- **Database Reader** — выполняет SQL-запросы к PostgreSQL.

**Технологии**: Python, Streamlit, psycopg2, pandas

**Функционал**:
- Общая статистика (всего транзакций, количество фродов, средний скор)
- Динамика скоринга во времени (line chart)
- Распределение скорингов (histogram)
- Таблица последних подозрительных транзакций
- Автообновление данных

**Доступ**: http://localhost:8501

---

### Инфраструктурные компоненты

#### Apache Kafka

**Роль**: Message broker для потоковой передачи данных между сервисами.

**Конфигурация**:
- **Режим**: KRaft (без Zookeeper)
- **Топики**:
  - `transactions` — входной поток транзакций
  - `scores` — результаты скоринга
- **Retention**: 7 дней
- **Partitions**: 3 (для масштабирования)
- **Replication Factor**: 1 (для dev-окружения)

**Порт**: 9092

---

#### PostgreSQL

**Роль**: Хранилище результатов скоринга.

**Конфигурация**:
- **База данных**: `fraud`
- **Таблица**: `transaction_scores`
- **Индексы**: Primary key на `transaction_id`, индекс на `processed_at` для быстрой выборки последних записей

**Порт**: 5432

---

## Потоки данных

### 1. Основной поток обработки транзакций

```
CSV File → Transaction Producer → Kafka (transactions) 
→ Fraud Scoring Service (Consumer → Preprocessor → ML Model → Publisher) 
→ Kafka (scores) → Score Writer → PostgreSQL 
→ Web UI → Аналитик
```

**Описание**:
1. Transaction Producer читает транзакции из CSV-файла и публикует их в топик `transactions`.
2. Fraud Scoring Service потребляет сообщения из `transactions`, применяет препроцессинг и ML-модель, публикует результаты в топик `scores`.
3. Score Writer потребляет сообщения из `scores` и сохраняет их в PostgreSQL.
4. Web UI читает данные из PostgreSQL и отображает их аналитику.

**Время прохождения**: end-to-end latency < 200ms

---

### 2. Поток обновления модели

```
Data Scientist → Обучение модели (offline) 
→ Сохранение артефактов (catboost_model.cbm, feature_metadata.json) 
→ Docker Volume → Fraud Scoring Service → Перезагрузка модели
```

**Описание**:
1. Data Scientist обучает модель локально с использованием `source/train/train.py`.
2. Модель и метаданные сохраняются в `artifacts/`.
3. При пересборке Docker-образа новая модель загружается в Fraud Scoring Service.
4. Сервис автоматически использует обновлённую модель при следующем запуске.

---

## Паттерны проектирования

### 1. Event-Driven Architecture

Система построена на событийной архитектуре с использованием Kafka как event bus. Каждый сервис асинхронно обрабатывает события, что обеспечивает:
- **Масштабируемость**: можно добавлять consumer'ы для увеличения throughput.
- **Отказоустойчивость**: при падении одного сервиса остальные продолжают работу.
- **Декаплинг**: сервисы не зависят друг от друга напрямую.

### 2. Microservices

Система разделена на независимые микросервисы с чёткой ответственностью:
- **Transaction Producer**: генерация событий
- **Fraud Scorer**: обработка и скоринг
- **Score Writer**: персистентность данных
- **Web UI**: презентационный слой

### 3. Consumer/Producer Pattern

Использование Kafka consumer groups и producers обеспечивает:
- Балансировку нагрузки между экземплярами сервисов
- Гарантию доставки сообщений (at-least-once delivery)
- Возможность replay событий из Kafka

### 4. Database per Service

Каждый сервис работает со своим хранилищем данных:
- Kafka — для streaming данных
- PostgreSQL — для persistent storage результатов

---

## Масштабирование

### Горизонтальное масштабирование

**Fraud Scoring Service**:
```bash
docker compose up --scale fraud-scorer=3
```

При увеличении количества экземпляров Kafka автоматически распределит партиции между consumer'ами в группе `fraud-scorer`.

**Производительность**:
- 1 инстанс: ~300 транзакций/сек
- 3 инстанса: ~900 транзакций/сек
- N инстансов: ~300*N транзакций/сек (до лимита Kafka)

### Вертикальное масштабирование

Для увеличения производительности ML-инференса:
- Использовать GPU для CatBoost (требует пересборки модели с GPU-поддержкой)
- Увеличить CPU/RAM для контейнеров в `docker-compose.yml`

---

## Мониторинг и observability

### Логирование

Все сервисы используют структурированное логирование:
- **Уровень**: INFO (ERROR для критических ошибок)
- **Формат**: `%(asctime)s [%(levelname)s] %(name)s - %(message)s`
- **Вывод**: stdout (Docker logs)

### Метрики

Возможные метрики для мониторинга:
- **Kafka**: lag по топикам, throughput, partition distribution
- **Fraud Scorer**: latency инференса, error rate, throughput
- **PostgreSQL**: query performance, connection pool usage
- **Streamlit**: количество активных пользователей, time to first byte

### Health checks

Docker Compose включает health checks для критичных сервисов:
- **Kafka**: проверка доступности broker через `kafka-topics.sh`
- **PostgreSQL**: `pg_isready -U fraud`

---

## Безопасность

### Текущая реализация (dev-окружение)

- Kafka работает без аутентификации (PLAINTEXT)
- PostgreSQL использует простой пароль (`fraud/fraud`)
- Streamlit доступен без авторизации

### Рекомендации для production

1. **Kafka**: 
   - Включить SSL/TLS для шифрования
   - Настроить SASL для аутентификации
   - ACL для контроля доступа к топикам

2. **PostgreSQL**:
   - Использовать сильные пароли
   - Ограничить сетевой доступ (firewall rules)
   - Включить SSL для соединений

3. **Streamlit**:
   - Добавить аутентификацию (OAuth2/LDAP)
   - Использовать HTTPS (reverse proxy с nginx)
   - Rate limiting для защиты от DDoS

4. **Docker**:
   - Не использовать `:latest` теги
   - Сканировать образы на уязвимости (Trivy, Snyk)
   - Использовать non-root пользователей в контейнерах

---

## Развёртывание

### Локальное окружение (Development)

```bash
# Сборка и запуск всех сервисов
docker compose up --build

# Масштабирование fraud-scorer
docker compose up --scale fraud-scorer=3

# Остановка и очистка
docker compose down -v
```

### Production-окружение

Рекомендуется использовать:
- **Kubernetes** для оркестрации контейнеров
- **Helm charts** для управления конфигурацией
- **CI/CD pipeline** для автоматизированного деплоя (GitLab CI, GitHub Actions)
- **Infrastructure as Code** (Terraform, Ansible)

---

## Ограничения и будущие улучшения

### Текущие ограничения

1. **Одна модель**: система поддерживает только одну версию модели одновременно.
2. **Нет A/B тестирования**: невозможно сравнить несколько моделей в production.
3. **Отсутствие feature store**: признаки пересчитываются для каждой транзакции.
4. **Manual model deployment**: требуется пересборка Docker-образа для обновления модели.

### Roadmap

1. **Model Registry** (MLflow, Seldon Core):
   - Версионирование моделей
   - Rollback к предыдущим версиям
   - A/B тестирование

2. **Feature Store** (Feast, Tecton):
   - Кеширование признаков
   - Снижение latency
   - Переиспользование между offline и online inference

3. **Online Learning**:
   - Continuous training на актуальных данных
   - Адаптация к drift'у

4. **Monitoring & Alerting**:
   - Prometheus для метрик
   - Grafana для визуализации
   - AlertManager для алертов

5. **Data Quality**:
   - Валидация входных данных (Great Expectations)
   - Обнаружение аномалий
   - Monitoring model performance (precision, recall drift)

---

## Заключение

Система детекции фрода реализована как масштабируемый, отказоустойчивый потоковый конвейер на основе микросервисной архитектуры. Использование Apache Kafka обеспечивает высокую throughput и декаплинг компонентов, а CatBoost позволяет получать быстрые и точные предсказания.

Архитектура спроектирована с учётом принципов **event-driven design**, **separation of concerns** и готова к горизонтальному масштабированию при росте нагрузки.

